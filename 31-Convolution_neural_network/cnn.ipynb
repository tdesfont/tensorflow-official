{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4HI2mpwlrcn"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSPCom-KmApV"
   },
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLGkt5qiyz4E"
   },
   "source": [
    "This tutorial demonstrates training a simple [Convolutional Neural Network](https://developers.google.com/machine-learning/glossary/#convolutional_neural_network) (CNN) to classify [CIFAR images](https://www.cs.toronto.edu/~kriz/cifar.html). Because this tutorial uses the [Keras Sequential API](https://www.tensorflow.org/guide/keras/overview), creating and training our model will take just a few lines of code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m7KBpffWzlxH"
   },
   "source": [
    "### Import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRFxccghyMVo"
   },
   "source": [
    "### Download and prepare the CIFAR10 dataset\n",
    "\n",
    "\n",
    "The CIFAR10 dataset contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWoEqyMuXFF4"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wArwCTJJlUa"
   },
   "source": [
    "### Verify the data\n",
    "\n",
    "To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3PAELE2eSU9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1267860c50cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# The CIFAR labels happen to be arrays,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# which is why you need the extra index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAABvCAYAAAAwlZQ4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABYElEQVR4nO3UwU0DUQxAwf2IEsKZ7b+WpIicoQfTQFBYKRHwNHO1D5ae5DUzG//fy28fwGMIGSFkhJARQkYIGfF6ZPl0Os2+7086hXsul8vnzLzdmh0Kue/7dj6fH3MVh621rt/NvNYIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjFgz8/PltT62bbs+7xzueJ+Zt1uDQyH5u7zWCCEjhIwQMkLICCEjhIwQMkLIiC8Hohp/BhBaQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oewp-wYg31t9"
   },
   "source": [
    "### Create the convolutional base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQvqXpNyN3x"
   },
   "source": [
    "The 6 lines of code below define the convolutional base using a common pattern: a stack of [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers.\n",
    "\n",
    "As input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size. If you are new to these dimensions, color_channels refers to (R,G,B). In this example, you will configure our CNN to process inputs of shape (32, 32, 3), which is the format of CIFAR images. You can do this by passing the argument `input_shape` to our first layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9YmGQBQPrdn"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvDVFkg-2DPm"
   },
   "source": [
    "Let's display the architecture of our model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-C4XBg4UTJy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_j-AXYeZ2GO5"
   },
   "source": [
    "Above, you can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). The width and height dimensions tend to shrink as you go deeper in the network. The number of output channels for each Conv2D layer is controlled by the first argument (e.g., 32 or 64). Typically,  as the width and height shrink, you can afford (computationally) to add more output channels in each Conv2D layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_v8sVOtG37bT"
   },
   "source": [
    "### Add Dense layers on top\n",
    "To complete our model, you will feed the last output tensor from the convolutional base (of shape (3, 3, 64)) into one or more Dense layers to perform classification. Dense layers take vectors as input (which are 1D), while the current output is a 3D tensor. First, you will flatten (or unroll) the 3D output to 1D,  then add one or more Dense layers on top. CIFAR has 10 output classes, so you use a final Dense layer with 10 outputs and a softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRs95d6LUVEi"
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipGiQMcR4Gtq"
   },
   "source": [
    "Here's the complete architecture of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Yu_m-TZUWGX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNKXi-Gy3RO-"
   },
   "source": [
    "As you can see, our (3, 3, 64) outputs were flattened into vectors of shape (576) before going through two Dense layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3odqfHP4M67"
   },
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdDzI75PUXrG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5684 - accuracy: 0.4266 - val_loss: 1.2367 - val_accuracy: 0.5543\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 7s 130us/sample - loss: 1.1648 - accuracy: 0.5879 - val_loss: 1.1616 - val_accuracy: 0.5853\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 6s 130us/sample - loss: 1.0314 - accuracy: 0.6379 - val_loss: 1.0190 - val_accuracy: 0.6374\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 6s 129us/sample - loss: 0.9382 - accuracy: 0.6711 - val_loss: 0.9656 - val_accuracy: 0.6617\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 6s 129us/sample - loss: 0.8650 - accuracy: 0.6970 - val_loss: 0.9005 - val_accuracy: 0.6870\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 6s 129us/sample - loss: 0.8054 - accuracy: 0.7183 - val_loss: 0.9217 - val_accuracy: 0.6748\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 7s 131us/sample - loss: 0.7557 - accuracy: 0.7356 - val_loss: 0.9336 - val_accuracy: 0.6858\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 7s 132us/sample - loss: 0.7145 - accuracy: 0.7514 - val_loss: 0.9107 - val_accuracy: 0.6906\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 7s 134us/sample - loss: 0.6758 - accuracy: 0.7647 - val_loss: 0.8696 - val_accuracy: 0.7077\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 6s 130us/sample - loss: 0.6410 - accuracy: 0.7757 - val_loss: 0.8684 - val_accuracy: 0.7076\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKgyC5K_4O0d"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gtyDF0MKUcM7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 0.8927 - accuracy: 0.7076\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0LvwaKhtUdOo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cfJ8AR03gT5"
   },
   "source": [
    "Our simple CNN has achieved a test accuracy of over 70%. Not bad for a few lines of code! For another CNN style, see an example using the Keras subclassing API and a `tf.GradientTape` [here](https://www.tensorflow.org/tutorials/quickstart/advanced)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
